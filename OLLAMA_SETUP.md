# Configuration et Diagnostic Ollama

Ce guide vous aide √† configurer et diagnostiquer Ollama pour le parsing IA des recettes.

## üöÄ D√©marrage Rapide

### 1. D√©marrer le container Ollama

```bash
docker-compose up -d ollama
```

### 2. V√©rifier que le container fonctionne

```bash
docker ps | grep ollama
```

Vous devriez voir quelque chose comme :
```
easycook-ollama   Up 2 minutes   0.0.0.0:11434->11434/tcp
```

### 3. T√©l√©charger le mod√®le Mistral

```bash
docker exec easycook-ollama ollama pull mistral
```

### 4. Configurer les variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet (ou copiez `.env.example`) :

```bash
cp .env.example .env
```

Assurez-vous que ces variables sont d√©finies :

```env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
```

### 5. Tester la connexion

```bash
curl http://localhost:11434/api/tags
```

Vous devriez voir une r√©ponse JSON avec la liste des mod√®les.

## üîç Diagnostic

### Script automatique

Ex√©cutez le script de diagnostic pour v√©rifier l'√©tat complet :

```bash
bash scripts/check-ollama.sh
```

### V√©rifications manuelles

1. **Le container est-il d√©marr√© ?**
   ```bash
   docker ps | grep ollama
   ```

2. **Le port 11434 est-il expos√© ?**
   ```bash
   docker port easycook-ollama
   ```
   Devrait afficher : `11434/tcp -> 0.0.0.0:11434`

3. **L'API r√©pond-elle ?**
   ```bash
   curl http://localhost:11434/api/tags
   ```

4. **Le mod√®le Mistral est-il disponible ?**
   ```bash
   docker exec easycook-ollama ollama list
   ```

5. **V√©rifier les logs du container**
   ```bash
   docker logs easycook-ollama
   ```

### Endpoint de sant√©

Une fois le serveur de dev lanc√©, vous pouvez v√©rifier l'√©tat d'Ollama via :

```bash
curl http://localhost:3000/api/admin/health/ollama
```

## ‚ùå Probl√®mes courants

### "Connection refused" sur localhost:11434

**Cause** : Le container Ollama n'est pas d√©marr√© ou le port n'est pas expos√©.

**Solution** :
```bash
# Red√©marrer le container
docker-compose restart ollama

# Ou le d√©marrer s'il n'est pas actif
docker-compose up -d ollama
```

### "Model not found"

**Cause** : Le mod√®le Mistral n'a pas √©t√© t√©l√©charg√©.

**Solution** :
```bash
docker exec easycook-ollama ollama pull mistral
```

### "Service unavailable" dans l'admin

**Cause** : Les variables d'environnement ne sont pas configur√©es ou le container n'est pas accessible.

**Solutions** :
1. V√©rifiez que `.env` existe et contient `OLLAMA_BASE_URL=http://localhost:11434`
2. Red√©marrez le serveur de dev apr√®s avoir modifi√© `.env`
3. V√©rifiez que le container Ollama fonctionne

### Performance lente

**Cause** : Ollama utilise le CPU au lieu du GPU.

**Solution** : Si vous avez un GPU NVIDIA, utilisez le profil GPU :

```bash
docker-compose --profile gpu up -d ollama-gpu
```

## üê≥ Configuration Docker

### Mode CPU (par d√©faut)

```bash
docker-compose up -d ollama
```

Limites :
- 4 CPU cores maximum
- 4GB RAM maximum

### Mode GPU (n√©cessite NVIDIA GPU)

```bash
docker-compose --profile gpu up -d ollama-gpu
```

Avantages :
- Parsing beaucoup plus rapide
- Meilleure capacit√© de traitement

## üìù Logs et Debug

### Activer les logs d√©taill√©s

Les logs Ollama apparaissent automatiquement dans la console du serveur Nuxt avec le pr√©fixe `[Ollama]`.

### Logs du container

```bash
# Logs en temps r√©el
docker logs -f easycook-ollama

# Derni√®res 100 lignes
docker logs --tail 100 easycook-ollama
```

## üîß Commandes utiles

```bash
# Status des containers
docker-compose ps

# Red√©marrer Ollama
docker-compose restart ollama

# Arr√™ter Ollama
docker-compose stop ollama

# Supprimer et recr√©er
docker-compose down
docker-compose up -d ollama

# Entrer dans le container
docker exec -it easycook-ollama bash

# Lister les mod√®les
docker exec easycook-ollama ollama list

# Tester un mod√®le
docker exec -it easycook-ollama ollama run mistral "Hello"
```

## üìö Resources

- [Documentation Ollama](https://github.com/ollama/ollama)
- [Mod√®les disponibles](https://ollama.com/library)
- [Docker Compose reference](https://docs.docker.com/compose/)
